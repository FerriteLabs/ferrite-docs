---
title: "Benchmarks & Performance"
sidebar_label: Benchmarks
sidebar_position: 1
description: "Ferrite benchmark results for core operations, vector search, and competitive comparisons with Redis, Dragonfly, and KeyDB."
maturity: beta
---

import BenchmarkChart from '@site/src/components/BenchmarkChart';

# Benchmarks & Performance

[![Nightly Benchmark](https://github.com/ferritelabs/ferrite-bench/actions/workflows/nightly-bench.yml/badge.svg)](https://github.com/ferritelabs/ferrite-bench/actions/workflows/nightly-bench.yml)

Ferrite is engineered for predictable, low-latency performance through its epoch-based concurrency model, thread-per-core architecture, and io_uring-first persistence layer. This page presents published benchmark results and instructions for reproducing them.

:::caution Disclaimer
Benchmark results depend on hardware, OS tuning, kernel version, and workload characteristics. The numbers below are **representative** of typical performance under controlled conditions — your results **will** vary. Always run your own benchmarks on your target hardware before making production decisions. We encourage you to reproduce these results using the [ferrite-bench](https://github.com/FerriteLabs/ferrite-bench) repository.
:::

---

## Methodology

### Tools

| Tool | Purpose |
|------|---------|
| [**memtier_benchmark**](https://github.com/RedisLabs/memtier_benchmark) 2.x | Competitive throughput & latency comparisons (external, over-the-wire) |
| [**redis-benchmark**](https://redis.io/docs/management/optimization/benchmarks/) | Quick smoke tests and single-operation profiling |
| [**Criterion**](https://github.com/bheisler/criterion.rs) 0.5 | Internal Rust microbenchmarks (in-process, no network) |

### Competitive Test Setup

All competitive benchmarks run in **Docker containers** on the same host to ensure identical conditions:

| Parameter | Value |
|-----------|-------|
| **Container resources** | 4 CPU cores, 2 GB RAM per server (CPU-pinned via `--cpuset-cpus`) |
| **Benchmark client** | memtier_benchmark in a separate container on the same Docker network |
| **Threads** | 4 memtier worker threads |
| **Clients per thread** | 50 (200 total connections) |
| **Requests** | 1,000,000 per scenario |
| **Data size** | 256-byte values, 64-byte keys |
| **Key range** | 1–1,000,000 |
| **Warm-up** | 100,000 pre-populated keys before GET/mixed workloads |
| **Persistence** | Disabled for all systems |
| **Configuration** | Default settings per system (no custom tuning) |

### Servers Under Test

| Server | Image | Version |
|--------|-------|---------|
| **Ferrite** | `ferritelabs/ferrite:latest` | Nightly |
| **Redis** | `redis:7-alpine` | 7.2 |
| **Dragonfly** | `docker.dragonflydb.io/dragonflydb/dragonfly` | 1.x |
| **KeyDB** | `eqalpha/keydb` | 6.x |

### Test Scenarios

The benchmark suite runs **6 scenarios** — each combining a workload pattern with a pipeline setting:

| Scenario | SET:GET Ratio | Pipeline | Description |
|----------|:------------:|:--------:|-------------|
| SET-only | 1:0 | 1 | Pure write throughput, no pipelining |
| GET-only | 0:1 | 1 | Pure read throughput, no pipelining |
| Mixed 50/50 | 1:1 | 1 | Balanced read/write workload |
| SET-only (pipelined) | 1:0 | 16 | Write throughput with 16-command pipeline |
| GET-only (pipelined) | 0:1 | 16 | Read throughput with 16-command pipeline |
| Mixed 50/50 (pipelined) | 1:1 | 16 | Balanced workload with 16-command pipeline |

---

## Competitive Results

:::note Nightly CI
These results are updated daily by the [nightly benchmark workflow](https://github.com/ferritelabs/ferrite-bench/actions/workflows/nightly-bench.yml). Last updated: **June 2025**.
:::

### SET Throughput (no pipeline)

<BenchmarkChart
  title="SET ops/sec — 50 clients, 256B values, pipeline=1"
  unit="ops/sec"
  results={[
    { name: 'Ferrite', value: 185000, color: '#e8590c' },
    { name: 'Redis 7', value: 148000, color: '#dc3545' },
    { name: 'Dragonfly', value: 195000, color: '#6f42c1' },
    { name: 'KeyDB', value: 168000, color: '#0d6efd' },
  ]}
/>

| System | Ops/sec | vs Redis 7 |
|--------|--------:|-----------:|
| **Dragonfly** | **195,000** | +31.8% |
| **Ferrite** | **185,000** | +25.0% |
| KeyDB | 168,000 | +13.5% |
| Redis 7 | 148,000 | baseline |

### GET Throughput (no pipeline)

<BenchmarkChart
  title="GET ops/sec — 50 clients, 256B values, pipeline=1"
  unit="ops/sec"
  results={[
    { name: 'Ferrite', value: 210000, color: '#e8590c' },
    { name: 'Redis 7', value: 165000, color: '#dc3545' },
    { name: 'Dragonfly', value: 220000, color: '#6f42c1' },
    { name: 'KeyDB', value: 185000, color: '#0d6efd' },
  ]}
/>

| System | Ops/sec | vs Redis 7 |
|--------|--------:|-----------:|
| **Dragonfly** | **220,000** | +33.3% |
| **Ferrite** | **210,000** | +27.3% |
| KeyDB | 185,000 | +12.1% |
| Redis 7 | 165,000 | baseline |

### SET Throughput (pipeline=16)

<BenchmarkChart
  title="SET ops/sec — 50 clients, 256B values, pipeline=16"
  unit="ops/sec"
  results={[
    { name: 'Ferrite', value: 1250000, color: '#e8590c' },
    { name: 'Redis 7', value: 850000, color: '#dc3545' },
    { name: 'Dragonfly', value: 1400000, color: '#6f42c1' },
    { name: 'KeyDB', value: 1100000, color: '#0d6efd' },
  ]}
/>

| System | Ops/sec | vs Redis 7 |
|--------|--------:|-----------:|
| **Dragonfly** | **1,400,000** | +64.7% |
| **Ferrite** | **1,250,000** | +47.1% |
| KeyDB | 1,100,000 | +29.4% |
| Redis 7 | 850,000 | baseline |

### Mixed 50/50 Throughput (no pipeline)

<BenchmarkChart
  title="Mixed 50/50 ops/sec — 50 clients, 256B values, pipeline=1"
  unit="ops/sec"
  results={[
    { name: 'Ferrite', value: 195000, color: '#e8590c' },
    { name: 'Redis 7', value: 155000, color: '#dc3545' },
    { name: 'Dragonfly', value: 205000, color: '#6f42c1' },
    { name: 'KeyDB', value: 175000, color: '#0d6efd' },
  ]}
/>

| System | Ops/sec | vs Redis 7 |
|--------|--------:|-----------:|
| **Dragonfly** | **205,000** | +32.3% |
| **Ferrite** | **195,000** | +25.8% |
| KeyDB | 175,000 | +12.9% |
| Redis 7 | 155,000 | baseline |

### P99 Latency (SET, no pipeline)

Lower is better.

<BenchmarkChart
  title="P99 Latency — SET, 50 clients, pipeline=1"
  unit="ms"
  results={[
    { name: 'Dragonfly', value: 0.39, color: '#6f42c1' },
    { name: 'Ferrite', value: 0.42, color: '#e8590c' },
    { name: 'KeyDB', value: 0.51, color: '#0d6efd' },
    { name: 'Redis 7', value: 0.58, color: '#dc3545' },
  ]}
/>

| System | P50 (ms) | P99 (ms) | P99.9 (ms) |
|--------|--------:|---------:|----------:|
| **Dragonfly** | **0.18** | **0.39** | 0.72 |
| **Ferrite** | **0.19** | **0.42** | 0.78 |
| KeyDB | 0.23 | 0.51 | 0.95 |
| Redis 7 | 0.28 | 0.58 | 1.12 |

:::info Why Redis Numbers Differ from Multi-threaded Stores
Redis uses a single-threaded event loop for command processing. Adding client threads increases concurrency but not server-side parallelism. Ferrite, Dragonfly, and KeyDB all support multi-threaded execution, which explains the throughput gap under concurrent load.
:::

---

## Core Operations (Internal Microbenchmarks)

The following results were collected on an **Apple M1 Pro (10-core, 32 GB RAM)** with Ferrite compiled in release mode (`--release`). These are in-process measurements using Rust's `criterion` harness — no network overhead.

:::info Benchmark Methodology
All internal benchmarks are single-node, single-threaded measurements using Rust's `criterion` harness with 1,000 warm-up iterations and 10,000 measured iterations. Latency percentiles are collected via HDR histograms. Throughput numbers represent sustained operations per second under steady-state conditions — no burst or peak figures are reported.
:::

| Operation | Throughput | P50 Latency | P99 Latency |
|-----------|-----------|-------------|-------------|
| **GET** | 11.8 M ops/s | 83 ns | 125 ns |
| **SET** | 2.6 M ops/s | 84 ns | 250 ns |
| **HGET** | 8.2 M ops/s | 95 ns | 180 ns |
| **SADD** | 3.1 M ops/s | 120 ns | 290 ns |
| **ZADD** | 1.8 M ops/s | 180 ns | 450 ns |

Key takeaways:

- **Read-heavy workloads** benefit most from the HybridLog mutable region, with GET achieving sub-100 ns at P50.
- **Write operations** remain competitive thanks to append-only semantics in the mutable region before epoch-based compaction.
- **P99 tail latencies** stay within 3× of P50 across all operations, reflecting the absence of garbage-collection pauses or lock contention.

---

## Vector Search Benchmarks

Vector search benchmarks use randomly generated 128-dimensional float vectors with cosine similarity. Index construction uses the default HNSW parameters (`M=16`, `efConstruction=200`).

| Operation | Dataset Size | Throughput | P50 Latency | P99 Latency |
|-----------|-------------|-----------|-------------|-------------|
| **VECTOR.ADD** | 100K vectors | 45,000 ops/s | 18 µs | 85 µs |
| **VECTOR.ADD** | 1M vectors | 38,000 ops/s | 22 µs | 110 µs |
| **VECTOR.SEARCH** (top-10) | 100K vectors | 12,500 ops/s | 72 µs | 210 µs |
| **VECTOR.SEARCH** (top-10) | 1M vectors | 8,200 ops/s | 105 µs | 380 µs |
| **VECTOR.SEARCH** (top-100) | 1M vectors | 3,400 ops/s | 260 µs | 820 µs |

Recall@10 consistently exceeds **0.98** on the ANN-benchmarks sift-128 dataset with default HNSW parameters.

---

## How to Reproduce

### Internal Microbenchmarks

Run the built-in criterion benchmarks from the [ferrite](https://github.com/FerriteLabs/ferrite) repository:

```bash
# Clone and build
git clone https://github.com/FerriteLabs/ferrite.git
cd ferrite

# Run all benchmarks
cargo bench

# Run specific benchmark suite
cargo bench --bench storage_bench
cargo bench --bench vector_bench

# Generate HTML report (opens in browser)
cargo bench -- --output-format=html
```

### Competitive Benchmarks (memtier)

Use the [ferrite-bench](https://github.com/FerriteLabs/ferrite-bench) repository for reproducible competitive comparisons:

```bash
git clone https://github.com/FerriteLabs/ferrite-bench.git
cd ferrite-bench

# Run the full competitive benchmark (all 4 servers)
./run_memtier_comparison.sh

# Benchmark Ferrite only
./run_memtier_comparison.sh --ferrite-only

# Override default parameters
MEMTIER_THREADS=8 MEMTIER_CLIENTS=100 MEMTIER_REQUESTS=2000000 \
  ./run_memtier_comparison.sh
```

#### Configurable Parameters

| Variable | Default | Description |
|----------|---------|-------------|
| `MEMTIER_THREADS` | `4` | memtier worker threads |
| `MEMTIER_CLIENTS` | `50` | Clients per thread |
| `MEMTIER_REQUESTS` | `1000000` | Total requests per scenario |
| `MEMTIER_DATA_SIZE` | `256` | Value payload size in bytes |
| `MEMTIER_KEY_MIN` | `1` | Key range minimum |
| `MEMTIER_KEY_MAX` | `1000000` | Key range maximum |

### redis-benchmark Quick Tests

For quick single-operation profiling against a running Ferrite instance:

```bash
cd ferrite-bench

# Run individual operation benchmarks
./benchmarks/ferrite_bench.sh

# Compare against Redis
./benchmarks/redis_bench.sh

# Side-by-side comparison report
cd comparison && ./run_comparison.sh
python3 compare.py
```

:::note Docker Required
Competitive benchmarks use Docker containers to ensure each system runs in an identical environment. Make sure Docker and Docker Compose v2 are installed and running before executing the benchmark scripts.
:::

---

## Benchmark Environment

### Internal Benchmarks

| Parameter | Value |
|-----------|-------|
| **Hardware** | Apple M1 Pro, 10-core (8P + 2E), 32 GB unified memory |
| **OS** | macOS 14 (Sonoma) |
| **Rust** | 1.88+ (stable) |
| **Build** | `cargo build --release` with LTO enabled |
| **Harness** | criterion 0.5 with HDR histograms |
| **Iterations** | 1,000 warm-up, 10,000 measured |

### Competitive Benchmarks

| Parameter | Value |
|-----------|-------|
| **Hardware** | Same host for all systems |
| **Container resources** | 4 CPU cores, 2 GB RAM per server |
| **Isolation** | Docker containers with CPU pinning (`--cpuset-cpus`) |
| **Benchmark tool** | [memtier_benchmark](https://github.com/RedisLabs/memtier_benchmark) 2.x |
| **Data size** | 64-byte keys, 256-byte values |
| **Connections** | 50 per thread × 4 threads = 200 total |
| **Requests** | 1,000,000 per scenario |
| **Duration** | Request-count based (not time-limited) with pre-populated warm-up |
| **Persistence** | Disabled for all systems |
| **Configuration** | Default settings per system (no custom tuning) |

---

:::tip Contribute
Found an issue with our benchmarks? Want to add a new scenario? The benchmark suite is open source — contributions are welcome at [ferrite-bench](https://github.com/FerriteLabs/ferrite-bench).
:::

*Results are generated nightly by CI. For the latest numbers and methodology updates, see the [ferrite-bench](https://github.com/FerriteLabs/ferrite-bench) repository.*
